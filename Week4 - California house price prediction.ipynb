{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression for house price prediction\n",
    "\n",
    "1. Linear regression(with normal equation and iterativee optimisation procedure)\n",
    "2. Polynomial regression\n",
    "3. Regularised regression model - ridge and lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(306)\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch dataset\n",
    "features, labels = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "\n",
    "# train-test split\n",
    "com_train_features, test_features, com_train_labels, test_labels = train_test_split(features, labels, random_state=42)\n",
    "# train --> train + dev split\n",
    "train_features, dev_features, train_labels, dev_labels = train_test_split(com_train_features, com_train_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_pipeline = Pipeline([(\"feature_scaling\", StandardScaler()),\n",
    "                                (\"lin_reg\", LinearRegression())])\n",
    "\n",
    "lin_reg_cv_results = cross_validate(lin_reg_pipeline,\n",
    "                                    com_train_features,\n",
    "                                    com_train_labels,\n",
    "                                    cv=cv,\n",
    "                                    scoring=\"neg_mean_absolute_error\",\n",
    "                                    return_train_score=True,\n",
    "                                    return_estimator=True)\n",
    "\n",
    "lin_reg_train_error = -1 * lin_reg_cv_results['train_score'] \n",
    "lin_reg_test_error = -1 * lin_reg_cv_results['test_score']\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the train set:\\n\"\n",
    "        f\"{lin_reg_train_error.mean():.3f} +/- {lin_reg_train_error.std():.3f}\")\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the test set:\\n\"\n",
    "        f\"{lin_reg_test_error.mean():.3f} +/- {lin_reg_test_error.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_pipeline = Pipeline([(\"feature_scaling\", StandardScaler()),\n",
    "                        (\"sgd\", SGDRegressor(max_iter=np.ceil(1e6/com_train_features.shape[0]),\n",
    "                                            early_stopping=True,\n",
    "                                            eta0 = 1e-4,\n",
    "                                            tol=1e-5,\n",
    "                                            learning_rate='constant',\n",
    "                                            validation_fraction=0.1,\n",
    "                                            n_iter_no_change=5,\n",
    "                                            average=10,\n",
    "                                            random_state=42))])\n",
    "\n",
    "sgd_reg_cv_results = cross_validate(sgd_reg_pipeline,\n",
    "                                    com_train_features,\n",
    "                                    com_train_labels,\n",
    "                                    cv=cv,\n",
    "                                    scoring=\"neg_mean_absolute_error\",\n",
    "                                    return_train_score=True,\n",
    "                                    return_estimator=True)\n",
    "\n",
    "sgd_reg_train_error = -1 * sgd_reg_cv_results['train_score'] \n",
    "sgd_reg_test_error = -1 * sgd_reg_cv_results['test_score']\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the train set:\\n\"\n",
    "        f\"{sgd_reg_train_error.mean():.3f} +/- {sgd_reg_train_error.std():.3f}\")\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the test set:\\n\"\n",
    "        f\"{sgd_reg_test_error.mean():.3f} +/- {sgd_reg_test_error.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_pipeline = Pipeline([(\"poly\", PolynomialFeatures(degree=2)),\n",
    "                            (\"feature_scaling\", StandardScaler()),\n",
    "                            (\"lin_reg\", LinearRegression())])\n",
    "\n",
    "poly_reg_cv_results = cross_validate(poly_reg_pipeline,\n",
    "                                    com_train_features,\n",
    "                                    com_train_labels,\n",
    "                                    cv=cv,\n",
    "                                    scoring=\"neg_mean_absolute_error\",\n",
    "                                    return_train_score=True,\n",
    "                                    return_estimator=True)\n",
    "\n",
    "poly_reg_train_error = -1 * poly_reg_cv_results['train_score'] \n",
    "poly_reg_test_error = -1 * poly_reg_cv_results['test_score']\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the train set:\\n\"\n",
    "        f\"{poly_reg_train_error.mean():.3f} +/- {poly_reg_train_error.std():.3f}\")\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the test set:\\n\"\n",
    "        f\"{poly_reg_test_error.mean():.3f} +/- {poly_reg_test_error.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use only inteeraction terms in polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_pipeline = Pipeline([(\"poly\", PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "                            (\"feature_scaling\", StandardScaler()),\n",
    "                            (\"lin_reg\", LinearRegression())])\n",
    "\n",
    "poly_reg_cv_results = cross_validate(poly_reg_pipeline,\n",
    "                                    com_train_features,\n",
    "                                    com_train_labels,\n",
    "                                    cv=cv,\n",
    "                                    scoring=\"neg_mean_absolute_error\",\n",
    "                                    return_train_score=True,\n",
    "                                    return_estimator=True)\n",
    "\n",
    "poly_reg_train_error = -1 * poly_reg_cv_results['train_score'] \n",
    "poly_reg_test_error = -1 * poly_reg_cv_results['test_score']\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the train set:\\n\"\n",
    "        f\"{poly_reg_train_error.mean():.3f} +/- {poly_reg_train_error.std():.3f}\")\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the test set:\\n\"\n",
    "        f\"{poly_reg_test_error.mean():.3f} +/- {poly_reg_test_error.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out which degree polynomial is best suited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "train_scores, test_scores = validation_curve(\n",
    "                                            poly_reg_pipeline, com_train_features, com_train_labels, param_name=\"poly__degree\",\n",
    "                                            param_range=degree, cv=cv, scoring=\"neg_mean_absolute_error\",\n",
    "                                            n_jobs=2)\n",
    "\n",
    "train_errors, test_errors = -train_scores, -test_scores\n",
    "\n",
    "plt.plot(degree, train_errors.mean(axis=1), 'b-x', label='Training error')\n",
    "plt.plot(degree, test_errors.mean(axis=1), 'r-x', label='Test error')\n",
    "plt.legend()\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"Mean absolute error ($k$)\")\n",
    "_ = plt.title(\"Validation curve for polynomial regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best degree = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_pipeline = Pipeline([(\"poly\", PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "                            (\"feature_scaling\", StandardScaler()),\n",
    "                            (\"ridge\", Ridge(alpha=0.5))])\n",
    "\n",
    "ridge_reg_cv_results = cross_validate(ridge_reg_pipeline,\n",
    "                                    com_train_features,\n",
    "                                    com_train_labels,\n",
    "                                    cv=cv,\n",
    "                                    scoring=\"neg_mean_absolute_error\",\n",
    "                                    return_train_score=True,\n",
    "                                    return_estimator=True)\n",
    "\n",
    "ridge_reg_train_error = -1 * ridge_reg_cv_results['train_score'] \n",
    "ridge_reg_test_error = -1 * ridge_reg_cv_results['test_score']\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the train set:\\n\"\n",
    "        f\"{ridge_reg_train_error.mean():.3f} +/- {ridge_reg_train_error.std():.3f}\")\n",
    "\n",
    "print(f\"Mean absolute error of linear regression model on the test set:\\n\"\n",
    "        f\"{ridge_reg_test_error.mean():.3f} +/- {ridge_reg_test_error.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPT for ridge regularisation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.logspace(-4, 0, num=20)\n",
    "ridge_reg_pipeline = Pipeline([(\"poly\", PolynomialFeatures(degree=2)),\n",
    "                            (\"feature_scaling\", StandardScaler()),\n",
    "                            (\"ridge_cv\", RidgeCV(alphas=alpha_list,\n",
    "                                                cv=cv,\n",
    "                                                scoring=\"neg_mean_absolute_error\"))])\n",
    "\n",
    "ridge_reg_cv_results = ridge_reg_pipeline.fit(com_train_features, com_train_labels)\n",
    "\n",
    "print(\"The score with the best alpha is: \",\n",
    "        f\"{ridge_reg_cv_results[-1].best_score_:.3f}\")\n",
    "\n",
    "print(\"The error with the best alpha is: \",\n",
    "        f\"{-ridge_reg_cv_results[-1].best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best value of alpha is: \", ridge_reg_cv_results[-1].alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RidgeCV` with cross validation\n",
    "exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge HPT through `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid_pipeline = Pipeline([(\"poly\", PolynomialFeatures(degree=2)),\n",
    "                            (\"feature_scaling\", StandardScaler()),\n",
    "                            (\"ridge\", Ridge())])\n",
    "\n",
    "param_grid = {'poly__degree': (1,2,3),\n",
    "            'ridge__alpha': np.logspace(-4, 0, num=20)}\n",
    "\n",
    "ridge_grid_search = GridSearchCV(ridge_grid_pipeline,\n",
    "                                param_grid=param_grid,\n",
    "                                n_jobs=2,\n",
    "                                cv=cv,\n",
    "                                scoring=\"neg_mean_absolute_error\",\n",
    "                                return_train_score=True)\n",
    "\n",
    "ridge_grid_search.fit(com_train_features, com_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_error = -1 * ridge_grid_search.cv_results_['mean_train_score'][ridge_grid_search.best_index_]\n",
    "mean_test_error = -1 * ridge_grid_search.cv_results_['mean_test_score'][ridge_grid_search.best_index_]\n",
    "std_train_error = -1 * ridge_grid_search.cv_results_['std_train_score'][ridge_grid_search.best_index_]\n",
    "std_test_error = -1 * ridge_grid_search.cv_results_['std_test_score'][ridge_grid_search.best_index_]\n",
    "\n",
    "print(f\"Best Mean absolute error of polynomial ridge regression model on the train set:\\n\"\n",
    "        f\"{mean_train_error.mean():.3f} +/- {std_train_error.std():.3f}\")\n",
    "\n",
    "print(f\"Mean absolute error of polynomial ridge regression model on the test set:\\n\"\n",
    "        f\"{mean_test_error.mean():.3f} +/- {std_test_error.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameter value is:\", ridge_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
