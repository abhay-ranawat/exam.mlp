{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "Baseline models made by using `DummyRegression` and `permutation_test_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_split_cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LinearRegression` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_pipeline = Pipeline([(\"feature_scaling\", StandardScaler()),\n",
    "                                (\"lin_reg\", LinearRegression())])\n",
    "\n",
    "lin_reg_cv_results = cross_validate(lin_reg_pipeline, train_features,\n",
    "                                    train_labels, cv=shuffle_split_cv,\n",
    "                                    scoring=\"neg_mean_squared_error\",\n",
    "                                    n_jobs=2)\n",
    "\n",
    "lin_reg_errors = pd.Series(-lin_reg_cv_results[\"test_score\"],\n",
    "                            name=\"Linear regression error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DummyRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_regressor_baseline(strategy, constant_val=None, quantile_val=None):\n",
    "    \n",
    "    baseline_model_median = DummyRegressor(strategy=strategy,\n",
    "                                            constant=constant_val,\n",
    "                                            quantile=quantile_val)\n",
    "\n",
    "    baseline_median_cv_results = cross_validate(baseline_model_median,\n",
    "                                                train_features, train_labels,\n",
    "                                                cv=shuffle_split_cv,\n",
    "                                                scoring=\"neg_mean_absolute_error\",\n",
    "                                                n_jobs=2)\n",
    "    \n",
    "    return pd.Series(-baseline_median_cv_results[\"test_score\"],\n",
    "                            name=\"Dummy regressor error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_median_cv_results_error = dummy_regressor_baseline(strategy = 'median')\n",
    "baseline_mean_cv_results_error = dummy_regressor_baseline(strategy = 'mean')\n",
    "baseline_constant_cv_results_error = dummy_regressor_baseline(strategy = 'constant', constant_val=2)\n",
    "baseline_quantile_cv_results_error = dummy_regressor_baseline(strategy = 'quantile', quantile_val=0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the performance of these dummy regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_error_df = pd.concat([baseline_median_cv_results_error,\n",
    "                            baseline_mean_cv_results_error,\n",
    "                            baseline_constant_cv_results_error,\n",
    "                            baseline_quantile_cv_results_error],\n",
    "                            axis=1)\n",
    "            \n",
    "dummy_error_df.columns = ['Median cv', 'Mean cv', 'Constant cv', 'Quantile cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_error_df.plot.hist(bins=50, density=True, edgecolor=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.xlabel(\"Mean absolute error ($k$)\")\n",
    "_ = plt.title(\"Distribution of the testing errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `permutation_test_score`\n",
    "\n",
    "It permutes the target to generate randomised data and computes the emperical p-value against the null hypothesis, that the features and targets are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, permutation_score, pvalue = permutation_test_score(lin_reg_pipeline,\n",
    "                                                            train_features,\n",
    "                                                            train_labels,\n",
    "                                                            cv=shuffle_split_cv,\n",
    "                                                            scoring=\"neg_mean_absolute_error\",\n",
    "                                                            n_jobs=2, n_permutations=30)\n",
    "\n",
    "permutation_errors = pd.Series(-permutation_score, name=\"Permuted error\")\n",
    "\n",
    "print(permutation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.concat([lin_reg_errors, baseline_median_cv_results_error, permutation_errors],\n",
    "                        axis = 1)\n",
    "\n",
    "error_df.plot.hist(bins=50, density=True, edgecolor=\"black\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Mean absolute error ($k$)\")\n",
    "_ = plt.title(\"Distribution of the testing errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
