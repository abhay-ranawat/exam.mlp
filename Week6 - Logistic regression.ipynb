{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression: The Zero detector\n",
    "\n",
    "We will again solve the MNIST handwritten image recognition problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common imports\n",
    "import numpy as np\n",
    "from pprint import pprint \n",
    "\n",
    "#to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "#Sklearn specfic imports\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier, LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "#scipy \n",
    "from scipy.stats import loguniform\n",
    "\n",
    "#To plot pretty figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#global settings\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "mpl.rc('figure', figsize=(8,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all warning by sklearn\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X_pd, y_pd = fetch_openml('mnist_784', version=1, return_X_y=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_pd.to_numpy()\n",
    "y = y_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 9 # Choose a square number\n",
    "factor = int(np.sqrt(num_images))\n",
    "fig, ax = plt.subplots(nrows = factor, ncols = factor, figsize = (8, 6))\n",
    "idx_offset = 0 # take \"num_images\" starting from the index \"idx_offset\"\n",
    "for i in range(factor):\n",
    "    index = idx_offset + i*(factor)\n",
    "    for j in range(factor):\n",
    "        ax[i, j].imshow(X[index + j].reshape(28, 28), cmap = 'gray')\n",
    "        ax[i, j].set_title('Label:{0}'.format(str(y[index + j])))\n",
    "        ax[i, j].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "* Unlike perceptron, where scaling is optional, sigmoid requires scaling between 0 and 1\n",
    "* Do not apply mean centering as it removes zeros from the data. Zeros should be kept as zeros in the data.\n",
    "* we are not using pipeline, since there is just the one preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.histplot(data = np.int8(y_train), binwidth = 0.45, bins = 11)\n",
    "plt.xticks(ticks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "plt.xlabel('Class')\n",
    "plt.title('Distribution of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifcation: 0-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new variable names with all 1\n",
    "y_train_0 = np.zeros((len(y_train)))\n",
    "y_test_0 =  np.zeros((len(y_test)))\n",
    "\n",
    "#find indices of the digit 0 image\n",
    "indx_0 = np.where(y_train == '0')\n",
    "y_train_0[indx_0] = 1\n",
    "\n",
    "indx_0 = np.where(y_test == '0')\n",
    "y_test_0[indx_0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_images = 9 # Choose a square number\n",
    "factor = int(np.sqrt(num_images))\n",
    "fig, ax = plt.subplots(nrows = factor, ncols = factor, figsize = (8, 6))\n",
    "idx_offset = 0 # take \"num_images\" starting from the index \"idx_offset\"\n",
    "for i in range(factor):\n",
    "    index = idx_offset + i*(factor)\n",
    "    for j in range(factor):\n",
    "        ax[i, j].imshow(X[index + j].reshape(28, 28), cmap = 'gray')\n",
    "        ax[i, j].set_title('Label:{0}'.format(str(y_train_0[index + j])))\n",
    "        ax[i, j].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(y_train=='0'))\n",
    "print(np.where(y_train_0==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "\n",
    "Let's quickly construct a baseline model witht he following rule\n",
    "\n",
    "1. Count the number of samples per class\n",
    "2. The model always outputs the class which has highest number of samples.\n",
    "3. Then calculate the accuracy of the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = len(np.where(y_train_0 == 1)[0])\n",
    "num_neg = len(np.where(y_train_0 == 0)[0])\n",
    "print(num_pos, num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf = DummyClassifier(strategy='most_frequent')\n",
    "base_clf.fit(x_train, y_train_0)\n",
    "print('Training accuracy:{0:0.2f}'.format(base_clf.score(x_train, y_train_0)))\n",
    "print('Testing accuracy:{0:0.2f}'.format(base_clf.score(x_test, y_test_0)))\n",
    "print('Score: ', base_clf.score(x_train, y_train_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model with `SGDClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training without regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_sgd_clf = SGDClassifier(loss='log',\n",
    "                            penalty='l2',\n",
    "                            max_iter=1,\n",
    "                            warm_start=True,\n",
    "                            eta0=0.01,\n",
    "                            alpha=0,\n",
    "                            learning_rate='constant',\n",
    "                            random_state=1729)\n",
    "\n",
    "Loss = []\n",
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    bin_sgd_clf.fit(x_train, y_train_0)\n",
    "    y_pred = bin_sgd_clf.predict_proba(x_train)\n",
    "    Loss.append(log_loss(y_train_0, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(iterations), Loss)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy:{0:0.2f}'.format(bin_sgd_clf.score(x_train, y_train_0)))\n",
    "print('Testing accuracy:{0:0.2f}'.format(bin_sgd_clf.score(x_test, y_test_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train_0 = bin_sgd_clf.predict(x_train)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_train_0, y_hat_train_0, values_format='.5g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_0, y_hat_train_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SGDClassifier(loss='log',\n",
    "                            penalty='l2',\n",
    "                            max_iter=100,\n",
    "                            warm_start=False,\n",
    "                            eta0=0.01,\n",
    "                            alpha=0,\n",
    "                            learning_rate='constant',\n",
    "                            random_state=1729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_bin_clf = cross_validate(estimator, x_train, y_train_0, cv=5,\n",
    "                            scoring=['precision', 'recall', 'f1'],\n",
    "                            return_train_score=True,\n",
    "                            return_estimator=True)\n",
    "\n",
    "pprint(cv_bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = bin_sgd_clf.coef_\n",
    "bias = bin_sgd_clf.intercept_\n",
    "print('Dimension of weights w: {0}'.format(weights.shape))\n",
    "print('Bias: {0}'.format(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(0,784), weights[0,:])\n",
    "plt.xlabel('Feature index')\n",
    "plt.ylabel('Weight value')\n",
    "plt.ylim((np.min(weights)-5, np.max(weights)+5))\n",
    "plt.grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a lot of weights seems to have zero values. Let's find out how many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_w = weights.shape[1] - np.count_nonzero(weights)\n",
    "print('Number of weights with value zero: %f' %num_zero_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As such, regularisation is not required since there aren't any weight vectors which blow up. BUt we will go ahead for the purpose of demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_clf_sgd_l2 = SGDClassifier(loss='log',\n",
    "                                penalty = 'l2',\n",
    "                                alpha=0.001,\n",
    "                                max_iter=1,\n",
    "                                eta0=0.01,\n",
    "                                warm_start=True,\n",
    "                                learning_rate='constant',\n",
    "                                random_state=1729)\n",
    "\n",
    "Loss = []\n",
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    bin_clf_sgd_l2.fit(x_train, y_train_0)\n",
    "    y_pred = bin_clf_sgd_l2.predict_proba(x_train)\n",
    "    Loss.append(log_loss(y_train_0, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(iterations), Loss)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = bin_clf_sgd_l2.coef_\n",
    "bias = bin_clf_sgd_l2.intercept_\n",
    "print('Dimension of weights w: {0}'.format(weights.shape))\n",
    "print('Bias: {0}'.format(bias)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(0,784), weights[0,:])\n",
    "plt.xlabel('Feature index')\n",
    "plt.ylabel('Weight value')\n",
    "plt.ylim((np.min(weights)-5, np.max(weights)+5))\n",
    "plt.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_w = weights.shape[1] - np.count_nonzero(weights)\n",
    "print('Number of weights with value zero: %f' %num_zero_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy %.2f' %bin_clf_sgd_l2.score(x_train, y_train_0))\n",
    "print('Testing accuracy %.2f' %bin_clf_sgd_l2.score(x_test, y_test_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train_0 = bin_clf_sgd_l2.predict(x_train)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_train_0, y_hat_train_0, values_format='.5g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_0, y_hat_train_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a few images and their prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_0 = bin_clf_sgd_l2.predict(x_test)\n",
    "num_images = 9 # Choose a square number\n",
    "factor = int(np.sqrt(num_images))\n",
    "fig, ax = plt.subplots(nrows = factor, ncols = factor, figsize = (8, 6))\n",
    "idx_offset = 0 # take \"num_images\" starting from the index \"idx_offset\"\n",
    "for i in range(factor):\n",
    "    index = idx_offset + i*(factor)\n",
    "    for j in range(factor):\n",
    "        ax[i, j].imshow(x_test[index + j].reshape(28, 28), cmap = 'gray')\n",
    "        ax[i, j].set_title('Prediction:{0}'.format(str(y_hat_test_0[index + j])))\n",
    "        ax[i, j].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_0 = np.where(y_test_0 == 1)\n",
    "\n",
    "zeroImgs = x_test[indx_0[0]]\n",
    "zeroLabls = y_hat_test_0[indx_0[0]]\n",
    "\n",
    "num_images = 9 # Choose a square number\n",
    "factor = int(np.sqrt(num_images))\n",
    "fig, ax = plt.subplots(nrows = factor, ncols = factor, figsize = (8, 6))\n",
    "idx_offset = 0 # take \"num_images\" starting from the index \"idx_offset\"\n",
    "for i in range(factor):\n",
    "    index = idx_offset + i*(factor)\n",
    "    for j in range(factor):\n",
    "        ax[i, j].imshow(zeroImgs[index + j].reshape(28, 28), cmap = 'gray')\n",
    "        ax[i, j].set_title('Prediction:{0}'.format(str(zeroLabls[index + j])))\n",
    "        ax[i, j].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate values to try\n",
    "lr_grid = loguniform(1e-2, 1e-1)\n",
    "\n",
    "estimator = SGDClassifier(loss='log',\n",
    "                            penalty='l2',\n",
    "                            max_iter=1,\n",
    "                            warm_start=True,\n",
    "                            eta0=0.01,\n",
    "                            alpha=0,\n",
    "                            learning_rate='constant',\n",
    "                            random_state=1729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = RandomizedSearchCV(estimator,\n",
    "                            param_distributions={'eta0': lr_grid},\n",
    "                            cv = 5,\n",
    "                            n_iter = 5,\n",
    "                            refit = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.fit(x_train, y_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(scores.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bin_clf = scores.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train_best_0 = best_bin_clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_0, y_hat_train_best_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = best_bin_clf.decision_function(x_train)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_0, y_scores)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "plt.xlabel('Threshold')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(precisions[:-1], recalls[:-1], \"b--\")\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train_0, y_scores)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(fpr, tpr, linewidth=2, label = 'Perceptron')\n",
    "plt.plot([0, 1], [0,1], 'k--', label = 'baseEstimator')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_train_0, y_scores)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same model with `LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training without regularisation\n",
    "\n",
    "* Set $C = \\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit = make_pipeline(MinMaxScaler(), LogisticRegression(random_state=1729,\n",
    "                                                                   solver='lbfgs',\n",
    "                                                                   C = np.infty))\n",
    "\n",
    "pipe_logit.fit(x_train, y_train_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "grid_Cs = [0, 1e-4, 1e-3, 1e-2, 1e-1, 1.0, 10.0, 100.0]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "logreg = LogisticRegression(C=1.0, random_state=1729)\n",
    "\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler),\n",
    "                        (\"logistic\", logreg)])\n",
    "\n",
    "pipe_logit_cv = GridSearchCV(pipe,\n",
    "                                param_grid={\"logistic__C\": grid_Cs},\n",
    "                                scoring='f1')\n",
    "\n",
    "pipe_logit_cv.fit(x_train, y_train_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `LogisticRegressionCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegressionCV(cv =5, scoring='f1', random_state=1729)\n",
    "logit_cv = make_pipeline(MinMaxScaler(), estimator)\n",
    "logit_cv.fit(x_train, y_train_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance Evaluation\n",
    "\n",
    "For \n",
    "* Logistic regression without regularisation\n",
    "* Best logistic regression classifier found through `GridSearchCV`\n",
    "* Best classifier found through `LogisticRegressionCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "\n",
    "lr_y_hat_0 = pipe_logit.predict(x_test)\n",
    "lr_gs_y_hat_0 = pipe_logit_cv.best_estimator_.predict(x_test)\n",
    "lr_cv_y_hat_0 = logit_cv.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_lr = precision_score(y_test_0, lr_y_hat_0)\n",
    "recall_lr = recall_score(y_test_0, lr_y_hat_0)\n",
    "\n",
    "precision_lr_gs = precision_score(y_test_0, lr_gs_y_hat_0)\n",
    "recall_lr_gs = recall_score(y_test_0, lr_gs_y_hat_0)\n",
    "\n",
    "precision_lr_cv = precision_score(y_test_0, lr_cv_y_hat_0)\n",
    "recall_lr_cv = recall_score(y_test_0, lr_cv_y_hat_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"LogReg: Precision = {precision_lr}, recall = {recall_lr}\")\n",
    "print(f\"GridSearch: Precision = {precision_lr_gs}, recall = {recall_lr_gs}\")\n",
    "print(f\"LogRegCV: Precision = {precision_lr_cv}, recall = {recall_lr_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Logistic regresssion with SGD(OneVsAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SGDClassifier(loss='log',\n",
    "                            penalty='l2',\n",
    "                            max_iter=1,\n",
    "                            warm_start=True,\n",
    "                            eta0=0.01,\n",
    "                            alpha=0,\n",
    "                            learning_rate='constant',\n",
    "                            random_state=1729)\n",
    "\n",
    "pipe_sgd_ovr = make_pipeline(MinMaxScaler(), estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = []\n",
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    pipe_sgd_ovr.fit(x_train, y_train)\n",
    "    y_pred = pipe_sgd_ovr.predict_proba(x_train)\n",
    "    Loss.append(log_loss(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(iterations), Loss)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sgd_ovr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pipe_sgd_ovr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_hat, values_format='.5g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit_ovr = make_pipeline(MinMaxScaler(),\n",
    "                                LogisticRegression(random_state=1729,\n",
    "                                                    solver='lbfgs',\n",
    "                                                    C = np.infty))\n",
    "\n",
    "pipe_logit_ovr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pipe_logit_ovr.predict(x_test)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_hat, values_format='.5g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
